name: Test Examples on Schedule

on:
  schedule:
    # Run weekly on Mondays at 2 AM UTC
    - cron: "0 2 * * 1"
  workflow_dispatch: # Allow manual triggering

env:
  PYTHON_VERSION: "3.13"

jobs:
  test-examples:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install latest released py-shiny
        run: |
          python -m pip install --upgrade pip
          pip install shiny

      - name: Test all examples
        id: test-examples
        run: |
          set -e

          # Initialize results tracking
          FAILED_EXAMPLES=()
          PASSED_EXAMPLES=()
          TOTAL=0

          echo "======================================"
          echo "Testing all example applications"
          echo "======================================"
          echo ""

          # Find all example directories with app.py
          for example_dir in examples/*/; do
            example_name=$(basename "$example_dir")

            # Skip if no app.py exists
            if [ ! -f "${example_dir}app.py" ]; then
              echo "Skipping $example_name (no app.py found)"
              continue
            fi

            TOTAL=$((TOTAL + 1))
            echo "======================================"
            echo "Testing: $example_name"
            echo "======================================"

            # Create isolated virtual environment for this example
            venv_dir=$(mktemp -d)
            log_file=$(mktemp)

            # Setup trap for cleanup
            cleanup() {
              # Kill app process if still running
              if [ -n "${APP_PID:-}" ]; then
                if kill -0 $APP_PID 2>/dev/null; then
                  kill $APP_PID 2>/dev/null || true
                  sleep 1
                  # Force kill if still running
                  if kill -0 $APP_PID 2>/dev/null; then
                    kill -9 $APP_PID 2>/dev/null || true
                  fi
                fi
                wait $APP_PID 2>/dev/null || true
              fi
              # Clean up temp files
              rm -f "$log_file"
              rm -rf "$venv_dir"
            }
            trap cleanup EXIT

            # Create and activate virtual environment
            python -m venv "$venv_dir"
            source "$venv_dir/bin/activate"

            # Install latest released py-shiny in the isolated environment
            pip install -q shiny

            # Install example-specific requirements if they exist
            if [ -f "${example_dir}requirements.txt" ]; then
              echo "Installing dependencies from requirements.txt..."
              if ! pip install -q -r "${example_dir}requirements.txt" 2>&1 | tee -a "$log_file"; then
                echo "Failed to install dependencies for $example_name"
                echo ""
                echo "Error output:"
                tail -20 "$log_file"
                FAILED_EXAMPLES+=("$example_name (dependency installation failed)")
                deactivate
                cleanup
                trap - EXIT
                echo ""
                continue
              fi
            fi

            # Find an available port
            PORT=$(python -c "import socket; s=socket.socket(); s.bind(('', 0)); print(s.getsockname()[1]); s.close()")
            echo "Starting application on port $PORT..."

            # Get absolute path to app.py
            APP_PATH=$(realpath "${example_dir}app.py")

            # Run the app from /tmp to avoid importing from the repo directory
            cd /tmp
            timeout 15s python -m shiny run "$APP_PATH" --port "$PORT" > "$log_file" 2>&1 &
            APP_PID=$!
            cd - > /dev/null

            # Wait for app to start (up to 5 seconds)
            STARTED=false
            for i in {1..10}; do
              sleep 0.5
              if kill -0 $APP_PID 2>/dev/null; then
                # Check if app is actually serving HTTP
                if curl -s -o /dev/null -w "%{http_code}" "http://localhost:$PORT" > /dev/null 2>&1; then
                  STARTED=true
                  break
                fi
              else
                # Process died
                break
              fi
            done

            # Check if process is still running and responding
            if ! $STARTED || ! kill -0 $APP_PID 2>/dev/null; then
              echo "Application failed to start or crashed immediately"
              echo ""
              echo "Error output:"
              cat "$log_file"
              FAILED_EXAMPLES+=("$example_name (startup failure)")
              deactivate
              cleanup
              trap - EXIT
              echo ""
              continue
            fi

            # Make HTTP request to verify it's working
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "http://localhost:$PORT" 2>/dev/null || echo "000")
            if [ "$HTTP_CODE" != "200" ]; then
              echo "Application started but returned HTTP $HTTP_CODE"
              echo ""
              echo "Log output:"
              cat "$log_file"
              FAILED_EXAMPLES+=("$example_name (HTTP $HTTP_CODE)")
              deactivate
              cleanup
              trap - EXIT
              echo ""
              continue
            fi

            # Check the log for errors - use more specific patterns to avoid false positives
            # Look for actual Python errors/exceptions with context
            if grep -E "^(Traceback \(most recent call last\)|.*Error: |.*Exception: )" "$log_file" > /dev/null || \
               grep -E "(raise |raised |ERROR |CRITICAL |Fatal )" "$log_file" > /dev/null; then
              echo "Detected errors or exceptions in output:"
              echo ""
              grep -E "^(Traceback \(most recent call last\)|.*Error: |.*Exception: |raise |raised |ERROR |CRITICAL |Fatal )" "$log_file" || true
              echo ""
              FAILED_EXAMPLES+=("$example_name (errors/exceptions detected)")
              echo "Test failed due to errors"
            else
              echo "Application started successfully with no errors"
              PASSED_EXAMPLES+=("$example_name")
            fi

            # Cleanup
            deactivate
            cleanup
            trap - EXIT
            echo ""
          done

          echo "======================================"
          echo "Test Summary"
          echo "======================================"
          echo ""
          echo "Total examples tested: $TOTAL"
          echo "Passed: ${#PASSED_EXAMPLES[@]}"
          echo "Failed: ${#FAILED_EXAMPLES[@]}"
          echo ""

          if [ ${#PASSED_EXAMPLES[@]} -gt 0 ]; then
            echo "Passed examples:"
            for example in "${PASSED_EXAMPLES[@]}"; do
              echo "  - $example"
            done
            echo ""
          fi

          if [ ${#FAILED_EXAMPLES[@]} -gt 0 ]; then
            echo "Failed examples:"
            for example in "${FAILED_EXAMPLES[@]}"; do
              echo "  - $example"
            done
            echo ""

            # Save failed examples for issue creation
            echo "FAILED_COUNT=${#FAILED_EXAMPLES[@]}" >> $GITHUB_OUTPUT
            {
              echo "FAILED_LIST<<EOF"
              for example in "${FAILED_EXAMPLES[@]}"; do
                echo "$example"
              done
              echo "EOF"
            } >> $GITHUB_OUTPUT

            exit 1
          else
            echo "All examples passed!"
            echo "FAILED_COUNT=0" >> $GITHUB_OUTPUT
          fi

          # Save passed examples for issue cleanup
          {
            echo "PASSED_LIST<<EOF"
            for example in "${PASSED_EXAMPLES[@]}"; do
              echo "$example"
            done
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Manage issues for failed/passed examples
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const failedList = '${{ steps.test-examples.outputs.FAILED_LIST }}'.split('\n').filter(x => x.trim());
            const passedList = '${{ steps.test-examples.outputs.PASSED_LIST }}'.split('\n').filter(x => x.trim());
            const runUrl = `${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}`;
            const labelName = 'example-test-failure';

            // Get all open issues with the example-test-failure label
            const { data: openIssues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: labelName,
              state: 'open'
            });

            // Create a map of example name to issue
            const issueMap = new Map();
            for (const issue of openIssues) {
              // Extract example name from issue title (format: "Example test failure: example-name")
              const match = issue.title.match(/^Example test failure: (.+)$/);
              if (match) {
                issueMap.set(match[1], issue);
              }
            }

            // Process failed examples
            for (const failedExample of failedList) {
              if (!failedExample) continue;

              // Extract example name (remove any parenthetical error info)
              const exampleName = failedExample.split(' (')[0].trim();

              if (!issueMap.has(exampleName)) {
                // Create new issue for this example
                const issueTitle = `Example test failure: ${exampleName}`;
                const issueBody = `## Example Test Failure

            The example \`${exampleName}\` is failing in the scheduled tests.

            ### Failure Details
            - **Status**: ${failedExample}
            - **Run Date**: ${new Date().toISOString().split('T')[0]}
            - **Workflow Run**: [View full logs](${runUrl})
            - **Python Version**: ${{ env.PYTHON_VERSION }}

            ### Next Steps
            1. Review the [workflow logs](${runUrl}) for detailed error messages
            2. Test the example locally with: \`cd examples/${exampleName} && python -m shiny run app.py\`
            3. Fix any startup errors, exceptions, or critical warnings
            4. Ensure all example dependencies are correctly specified in requirements.txt

            ---
            *This issue was automatically created by the \`test-examples-scheduled.yaml\` workflow and will be automatically closed when the example passes.*`;

                const newIssue = await github.rest.issues.create({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  title: issueTitle,
                  body: issueBody,
                  labels: [labelName, 'examples', 'bug']
                });
                console.log(`Created issue #${newIssue.data.number} for ${exampleName}`);
              } else {
                // Issue already exists, add a comment with the latest failure
                const issue = issueMap.get(exampleName);
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issue.number,
                  body: `Example still failing as of ${new Date().toISOString().split('T')[0]}.\n\n**Status**: ${failedExample}\n**Workflow Run**: [View logs](${runUrl})`
                });
                console.log(`Updated issue #${issue.number} for ${exampleName}`);
              }
            }

            // Process passed examples - close any open issues
            for (const passedExample of passedList) {
              if (!passedExample) continue;

              const exampleName = passedExample.trim();

              if (issueMap.has(exampleName)) {
                const issue = issueMap.get(exampleName);
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issue.number,
                  body: `âœ… Example is now passing as of ${new Date().toISOString().split('T')[0]}.\n\n**Workflow Run**: [View logs](${runUrl})\n\nClosing this issue automatically.`
                });
                await github.rest.issues.update({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issue.number,
                  state: 'closed'
                });
                console.log(`Closed issue #${issue.number} for ${exampleName} (now passing)`);
              }
            }
